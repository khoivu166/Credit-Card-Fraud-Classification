{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "a440a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "902ccefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows 3075\n",
      "The columns of the database Index(['Merchant_id', 'Transaction date', 'Average Amount/transaction/day',\n",
      "       'Transaction_amount', 'Is declined', 'Total Number of declines/day',\n",
      "       'isForeignTransaction', 'isHighRiskCountry', 'Daily_chargeback_avg_amt',\n",
      "       '6_month_avg_chbk_amt', '6-month_chbk_freq', 'isFradulent'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isFradulent\n",
       "False    2627\n",
       "True      448\n",
       "dtype: int64"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\",  true_values=[\"Y\"], false_values=[\"N\"])\n",
    "print(f\"Number of rows {len(df.index)}\")\n",
    "print(f\"The columns of the database {df.columns}\")\n",
    "df.value_counts(\"isFradulent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "54bf2ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFradulent\n",
       "False     15.824134\n",
       "True     181.917187\n",
       "Name: 6_month_avg_chbk_amt, dtype: float64"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xfields = [\n",
    "    'Average Amount/transaction/day',\n",
    "       'Transaction_amount', 'Is declined', 'Total Number of declines/day',\n",
    "       'isForeignTransaction', 'isHighRiskCountry', 'Daily_chargeback_avg_amt',\n",
    "       '6_month_avg_chbk_amt', '6-month_chbk_freq']\n",
    "\n",
    "df_shuffled = df.sample(frac=1) # shuffle the rows\n",
    "x = df_shuffled[xfields].to_numpy(dtype=np.float64)\n",
    "y = df_shuffled[\"isFradulent\"].to_numpy(dtype=np.float64)\n",
    "\n",
    "# the training data is the first 2000 rows, after shuffled\n",
    "training_data_x = x[:2000]\n",
    "training_data_y = y[:2000]\n",
    "\n",
    "# the test data is the remaining\n",
    "test_data_x = x[2000:]\n",
    "test_data_y = y[2000:]\n",
    "df_shuffled.groupby('isFradulent')['6_month_avg_chbk_amt'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959fcb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this to help you with what number goes with what field:\n",
      "0 = Average Amount/transaction/day\n",
      "1 = Transaction_amount\n",
      "2 = Is declined\n",
      "3 = Total Number of declines/day\n",
      "4 = isForeignTransaction\n",
      "5 = isHighRiskCountry\n",
      "6 = Daily_chargeback_avg_amt\n",
      "7 = 6_month_avg_chbk_amt\n",
      "8 = 6-month_chbk_freq\n"
     ]
    }
   ],
   "source": [
    "print(\"Run this to help you with what number goes with what field:\")\n",
    "for i, x in enumerate(xfields):\n",
    "    print(f\"{i} = {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd1d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created an accuracy metric to test hand-engineered classifcation algorithms\n",
    "def accuracy(y, yhat):\n",
    "    correct = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == yhat[i]:\n",
    "            correct += 1\n",
    "    percentage = correct / float(len(y))\n",
    "    return percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a577d090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# test accuracy function \n",
    "acc = accuracy([1, 0, 1], [1, 1, 0])\n",
    "print(f\"Accuracy is {acc}\") # should print 0.33..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7207afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_majority(x, theta):\n",
    "    # whatever the value of x, we return the theta\n",
    "    return theta\n",
    "\n",
    "# implement a train majority function that will look for the most common classification \n",
    "def train_majority(training_x, training_y):\n",
    "    # this function will have to determine which is more likely to \n",
    "    # be the value of y, one (true) or zero (false)\n",
    "    count1 = 0\n",
    "    count0 = 0\n",
    "    for i in training_y:\n",
    "        if i == 1:\n",
    "            count1 += 1\n",
    "        if i == 0:\n",
    "            count0 += 1\n",
    "    truePercentage = count1 / len(training_y)\n",
    "    falsePercentage = count0 / len(training_y)\n",
    "    if(truePercentage > 0.50):\n",
    "        moreLikely = 1\n",
    "    elif(falsePercentage > 0.50):\n",
    "        moreLikely = 0\n",
    "    return moreLikely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d61379a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.852\n"
     ]
    }
   ],
   "source": [
    "# assign theta value to the most common classification \n",
    "theta = train_majority(training_data_x, training_data_y)\n",
    "\n",
    "# Make an array of prediction values based on the theta value\n",
    "test_data_yhat = [theta for i in range(len(training_data_y))]\n",
    "\n",
    "# Test accuracy\n",
    "print(\"Accuracy: \",accuracy(training_data_y, test_data_yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3e934",
   "metadata": {},
   "source": [
    "This would beat a classifier that returned random values because a random classifier would at best have 50% chance of having a correct classification. This majority classifier will at worse have a 51% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this to help you with what number goes with what field:\n",
      "0 = Average Amount/transaction/day\n",
      "1 = Transaction_amount\n",
      "2 = Is declined\n",
      "3 = Total Number of declines/day\n",
      "4 = isForeignTransaction\n",
      "5 = isHighRiskCountry\n",
      "6 = Daily_chargeback_avg_amt\n",
      "7 = 6_month_avg_chbk_amt\n",
      "8 = 6-month_chbk_freq\n"
     ]
    }
   ],
   "source": [
    "print(\"Run this to help you with what number goes with what field:\")\n",
    "for i, x in enumerate(xfields):\n",
    "    print(f\"{i} = {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "66d0d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement hand-engineered classification algorithm \n",
    "def classify_handwritten(x, theta):\n",
    "    \"\"\"Fraudulent transaction classifier. In this test example, we classify every foreign transaction as fraudulent. Transactions larger than theta[0] are also fraudulent\"\"\"\n",
    "\n",
    "    if x[1] > theta:\n",
    "        if x[5] == 1:\n",
    "            return 1\n",
    "        elif x[4] == 1:\n",
    "            return 1\n",
    "        elif x[3] > 3:\n",
    "            return 1\n",
    "        elif x[2] == 1:\n",
    "            return 1\n",
    "        elif x[6] >= 400:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "a723623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Values: \n",
      "0.8335\n",
      "0.844\n",
      "0.875\n",
      "0.902\n",
      "0.914\n",
      "0.9135\n",
      "0.911\n",
      "0.901\n",
      "Best Theta Value : 23000 Accuracy:  0.914\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "# test hand-engineered classifcation algo with different thetas to find the most accurate one \n",
    "theta = [1000 ,2000 ,5000 ,10000 ,23000, 23500 ,25000, 30000]\n",
    "bestVal = 0\n",
    "bestTheta = 0\n",
    "print(\"Accuracy Values: \")\n",
    "for i in range(len(theta)):\n",
    "    for j in range(len(training_data_x)):\n",
    "        test_data_yhat[j] = classify_handwritten(training_data_x[j], theta[i])\n",
    "    accuracyVal = accuracy(training_data_y, test_data_yhat)\n",
    "    print(accuracyVal)\n",
    "    if accuracyVal > bestVal:\n",
    "        bestTheta = theta[i]\n",
    "        bestVal = accuracyVal\n",
    "print(\"Best Theta Value :\", bestTheta, \"Accuracy: \", bestVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "86997918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914\n",
      "23000\n"
     ]
    }
   ],
   "source": [
    "# print best theta value and accuracy\n",
    "print(bestVal)\n",
    "print (bestTheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45601723",
   "metadata": {},
   "source": [
    "Based on my experiments, my hand-engineered classifier was able ot perform better than the majority classifier. My theta values were based upon the transaction amount that would possibly be a fraudulant transaction. The algorithm would then check if the country is a high-risk one and consider different features such as the a foreign transaction or multiple declines. The best accuracy value I received was a 0.914. Originally it was a little difficult to beat the majority classifier as I was overfitted the data, but after began to consider less features to allow for more generalization the accuracy became better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "1b91956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement logistic regression using the sklearn library\n",
    "\n",
    "def logRegression(max_iter, solver, X_train, y_train, X_test, y_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    bestScore = 0\n",
    "    bestSolver = ''\n",
    "    bestIter = 0\n",
    "    \n",
    "    logDef = LogisticRegression()\n",
    "    logDef.fit(X_train, y_train)\n",
    "    logDef.predict(X_test)\n",
    "    scoreWithoutParamters = logDef.score(X_test, y_test)\n",
    "    print(\"Score with no parameters changed: \", scoreWithoutParamters)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in solver:\n",
    "        for j in max_iter:\n",
    "            log = LogisticRegression(solver=i, max_iter=j)\n",
    "            log.fit(X_train, y_train)\n",
    "            log.predict(X_test)\n",
    "            score = log.score(X_test, y_test)\n",
    "            if score > bestScore:\n",
    "                bestScore = score\n",
    "                bestSolver = i\n",
    "                bestIter = j\n",
    "    print(\"Score with best parameters\")\n",
    "    print(bestScore, bestSolver, bestIter)\n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "7af53924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khoivu166/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with no parameters changed:  0.986046511627907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khoivu166/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with best parameters\n",
      "0.9953488372093023 lbfgs 1000\n",
      "None\n",
      "Time:  9.076490640640259\n"
     ]
    }
   ],
   "source": [
    "# test the sklearn logistic regression \n",
    "import time\n",
    "start = time.time()\n",
    "solver = ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga']\n",
    "max_iter = [1000, 5000, 7000, 10000]\n",
    "\n",
    "print(logRegression(max_iter, solver, training_data_x, training_data_y, test_data_x, test_data_y))\n",
    "end = time.time()\n",
    "print(\"Time: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf8d9c",
   "metadata": {},
   "source": [
    "Based on the experiments, the Logistic Regression classifier performed better than my hand-engineered classifer. My hand-engineered classifier had an accuracy of 0.914 where as the sklearn Logisitic Regression had an accuracy of 0.995. In my experiments with the sklearn logistic regression, I experimented with the different solvers that library offered and performed various amounts of the iterations on each solver. The solver that performed the best was the \"lbfgs\" solver that received the accuracy score of 0.995. I also experimented with the logistic regression classifier with no paramters and it performed slightly worse with a score of 0.986. The sklearn logistic classifier was much easier at allowing the tweaking of my parameters however the training time was slightly slower compared to my hand-engineered one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "9663e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sklearn random forest algorithm \n",
    "def randomForest(X_train, y_train, X_test, y_test, n_estimators, max_depth):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    bestScore = 0\n",
    "    bestEstimator = 0\n",
    "    bestDepth = 0\n",
    "    \n",
    "    randForest = RandomForestClassifier()\n",
    "    randForest.fit(X_train, y_train)\n",
    "    preds = randForest.predict(X_test)\n",
    "    print(\"Accuracy with no parameters: \" ,randForest.score(X_test, y_test))\n",
    "    \n",
    "    for i in n_estimators:\n",
    "        for j in max_depth:\n",
    "            randForestParam = RandomForestClassifier(n_estimators=i, max_depth=j)\n",
    "            randForestParam.fit(X_train, y_train)\n",
    "            pred = randForestParam.predict(X_test)\n",
    "            score = randForestParam.score(X_test, y_test)\n",
    "            if score > bestScore:\n",
    "                bestScore = score\n",
    "                bestEstimator = i\n",
    "                bestDepth = j\n",
    "    \n",
    "    print(\"Best Parameters: n_estimators: \", bestEstimator, \"depth: \", bestDepth)\n",
    "    print(\"Best Score: \", bestScore)       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "65e10363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with no parameters:  0.987906976744186\n",
      "Best Parameters: n_estimators:  100 depth:  10\n",
      "Best Score:  0.9906976744186047\n"
     ]
    }
   ],
   "source": [
    "# test the Random Forest algorithm with different parameters\n",
    "n_estimators = [100, 500, 700, 1000]\n",
    "max_depth = [None, 1, 5, 10, 15]\n",
    "\n",
    "\n",
    "randomForest(training_data_x, training_data_y, test_data_x, test_data_y, n_estimators, max_depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f1f3",
   "metadata": {},
   "source": [
    "The experiments I performed for the random forest classifier consisted of experiments the n_estimators and max_depth parameters. I first ran one test with no parameters passed and received an accuracy of 0.987. I then created an array of different values for the two parameters I was working with and ran the classifier through each parameter value. The best accuracy I received was 0.991 with 100 estimators and a depth of 10. Tweaking the parameters made the accuracy slightly better with a 1% increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "cc373403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sklearn adaboost  \n",
    "def adaboost(X_train, y_train, X_test, y_test, n_estimators, learning_rate, algo):\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    \n",
    "    bestScore = 0\n",
    "    bestAlgo = ''\n",
    "    bestRate = 0\n",
    "    bestEstimator = 0\n",
    "    \n",
    "    ada = AdaBoostClassifier()\n",
    "    ada.fit(X_train, y_train)\n",
    "    pred = ada.predict(X_test)\n",
    "    score = ada.score(X_test, y_test)\n",
    "    print(\"Score with no parameters: \", score)\n",
    "    \n",
    "    for i in algo:\n",
    "        for j in learning_rate:\n",
    "            for k in n_estimators:\n",
    "                adaParam = AdaBoostClassifier(n_estimators=k, learning_rate=j, algorithm=i)\n",
    "                adaParam.fit(X_train, y_train)\n",
    "                predParam = adaParam.predict(X_test)\n",
    "                scoreParam = adaParam.score(X_test, y_test)\n",
    "                if scoreParam > bestScore:\n",
    "                    bestScore = scoreParam\n",
    "                    bestAlgo = i\n",
    "                    bestRate = j\n",
    "                    bestEstimator = k\n",
    "    print(\"Best Parameters: Algorithm: \", bestAlgo, \"Learning Rate: \", bestRate, \"n_estimators: \", bestEstimator)\n",
    "    print(\"Best Score: \", bestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "294dde6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with no parameters:  0.9944186046511628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khoivu166/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 13, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 13, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 13, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/khoivu166/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 13, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: Algorithm:  SAMME.R Learning Rate:  1.0 n_estimators:  100\n",
      "Best Score:  0.9953488372093023\n"
     ]
    }
   ],
   "source": [
    "# test adaboost with different parameters \n",
    "n_estimators = [50, 100, 150, 200]\n",
    "learning_rate = [1.0, 1.5, 2.0, 2.5]\n",
    "algo = ['SAMME', 'SAMME.R']\n",
    "\n",
    "adaboost(training_data_x, training_data_y, test_data_x, test_data_y, n_estimators, learning_rate, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96077a1",
   "metadata": {},
   "source": [
    "During my experiments, I tested the Algorithm, Learning_rate, and n_estimators parameters. I first tested adaboost with no parameters and got an accuracy of 0.994. After I created an array of the three parameters I was testing and filled them with various values. I then tested all combinations of these parameter values and got a best accuracy of 0.995 which is a slight improvement from the default test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7e2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
